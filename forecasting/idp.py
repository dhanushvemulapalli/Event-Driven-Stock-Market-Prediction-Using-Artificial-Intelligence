# -*- coding: utf-8 -*-
"""idp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14rA56GnTvW83Bh5Ruu3UP7H3enHSZXsF
"""

!pip install requests newsapi-python vaderSentiment alpaca-trade-api

import pandas as pd

stockprices = pd.read_csv("/content/drive/MyDrive/STOCK prices/all_stocks_2006-01-01_to_2018-01-01.csv")

stockprices.head()

stockprices.drop(columns=['Date','Open','High','Low'], inplace=True)

stockprices.head()

def transform_stock_data_no_overlap(df, window_size=22):
    """
    Transform stock data to a rolling window format, ensuring no overlap between stocks.

    Args:
    - df (DataFrame): DataFrame with 'Close', 'Volume', and 'Name' columns.
    - window_size (int): Number of days for the rolling window.

    Returns:
    - DataFrame: Transformed DataFrame with rolling window columns.
    """
    all_transformed = []

    # Group by 'Name' to avoid overlaps between stocks
    for name, group in df.groupby("Name"):
        group = group.reset_index(drop=True)  # Reset index for the group
        transformed_data = []
        for i in range(len(group) - window_size + 1):
            # Extract the rolling window
            window = group.iloc[i:i + window_size]
            # Flatten the 'Close' and 'Volume' columns
            flattened = window[['Close', 'Volume']].values.flatten()
            transformed_data.append(flattened)

        # Correctly generate column names dynamically
        columns = []
        for i in range(1, window_size + 1):
            columns.append(f"close{i}")
            columns.append(f"vol{i}")

        # Create the transformed DataFrame for this stock
        transformed_df = pd.DataFrame(transformed_data, columns=columns)
        transformed_df['Name'] = name  # Add the stock name to the output
        all_transformed.append(transformed_df)

    # Combine all groups into a single DataFrame
    return pd.concat(all_transformed, ignore_index=True)



# Example usage
stockpriceseries = transform_stock_data_no_overlap(stockprices)
stockpriceseries.head()

stockpriceseries.drop(columns=['Name'], inplace=True)

from sklearn.model_selection import train_test_split
X = stockpriceseries.drop('close22', axis=1)
X = stockpriceseries.drop('vol22', axis=1)

y = stockpriceseries['close22']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

y_test.head()

!pip install lazypredict

!pip install "dask[dataframe]"

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Initialize and train model
lr = LinearRegression()
lr.fit(X_train, y_train)

# Predictions and evaluation
y_pred = lr.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
rmse = mse ** 0.5
r2 = r2_score(y_test, y_pred)

print(f"Linear Regression RMSE: {rmse}")
print(f"Linear Regression R^2: {r2}")

from sklearn.linear_model import Ridge

# Initialize and train model
ridge = Ridge(alpha=1.0)  # You can experiment with different alpha values
ridge.fit(X_train, y_train)

# Predictions and evaluation
y_pred_ridge = ridge.predict(X_test)
mse_ridge = mean_squared_error(y_test, y_pred_ridge)
rmse_ridge = mse_ridge ** 0.5
r2_ridge = r2_score(y_test, y_pred_ridge)

print(f"Ridge Regression RMSE: {rmse_ridge}")
print(f"Ridge Regression R^2: {r2_ridge}")

from sklearn.linear_model import Lasso

# Initialize and train model
lasso = Lasso(alpha=0.01)  # Tune alpha for better performance
lasso.fit(X_train, y_train)

# Predictions and evaluation
y_pred_lasso = lasso.predict(X_test)
mse_lasso = mean_squared_error(y_test, y_pred_lasso)
rmse_lasso = mse_lasso ** 0.5
r2_lasso = r2_score(y_test, y_pred_lasso)

print(f"Lasso Regression RMSE: {rmse_lasso}")
print(f"Lasso Regression R^2: {r2_lasso}")

from sklearn.ensemble import RandomForestRegressor

# Initialize and train model
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Predictions and evaluation
y_pred_rf = rf.predict(X_test)
mse_rf = mean_squared_error(y_test, y_pred_rf)
rmse_rf = mse_rf ** 0.5
r2_rf = r2_score(y_test, y_pred_rf)

print(f"Random Forest RMSE: {rmse_rf}")
print(f"Random Forest R^2: {r2_rf}")

import xgboost as xgb
from sklearn.metrics import mean_squared_error, r2_score

# Initialize and train model
xg_reg = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
xg_reg.fit(X_train, y_train)

# Predictions and evaluation
y_pred_xg = xg_reg.predict(X_test)
mse_xg = mean_squared_error(y_test, y_pred_xg)
rmse_xg = mse_xg ** 0.5
r2_xg = r2_score(y_test, y_pred_xg)

print(f"XGBoost RMSE: {rmse_xg}")
print(f"XGBoost R^2: {r2_xg}")

from sklearn.model_selection import cross_val_score

# Evaluate using 5-fold cross-validation
cv_scores_lr = cross_val_score(lr, X, y, cv=5, scoring='neg_mean_squared_error')
cv_scores_rf = cross_val_score(rf, X, y, cv=5, scoring='neg_mean_squared_error')
cv_scores_xg = cross_val_score(xg_reg, X, y, cv=5, scoring='neg_mean_squared_error')

print(f"Linear Regression CV RMSE: {-cv_scores_lr.mean()**0.5}")
print(f"Random Forest CV RMSE: {-cv_scores_rf.mean()**0.5}")
print(f"XGBoost CV RMSE: {-cv_scores_xg.mean()**0.5}")

# train_size = int(0.8 * len(stockpriceseries))
# train_data, test_data = stockpriceseries[:train_size], stockpriceseries[train_size:]

# train_data.shape
